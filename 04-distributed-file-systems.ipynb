{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Distributed File Systems </center>\n",
    "\n",
    "#### <center> Linh B. Ngo </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> How to arrange read/write accesses with processes running on computer that are part of a computing cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Networked File System **\n",
    "- Allow transparent access to files stored on a remote disk\n",
    "\n",
    "** Clustered File System **\n",
    "- Allow transparent access to files stored on a large set of disks, which could be distributed across multiple computers \n",
    "\n",
    "** Parallel File System **\n",
    "- Enable parallel access to files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Networked File System ** \n",
    "\n",
    "<img src=\"pictures/distributed-file-systems/sun.jpg\" height=\"42\">\n",
    "\n",
    "*Sandberg, R., Goldberg, D., Kleiman, S., Walsh, D., & Lyon, B. (1985, June). Design and implementation of the Sun network filesystem. In Proceedings of the Summer USENIX conference (pp. 119-130)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Sun Network Filesystem Protocol (NFS)\n",
    "- Current version: 4.2v\n",
    "- Design Goals\n",
    "  - Machine and operating system independence\n",
    "  - Crash recovery\n",
    "  - Transparent access\n",
    "  - UNIX semantics maintained on client\n",
    "  - Reasonable performance (target 80% as fast as local disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "NFS Design:\n",
    "- NFS Protocol\n",
    "- Server side\n",
    "- Client side    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "NFS Protocol:\n",
    "- Remote Procedure Call mechanism\n",
    "- Stateless protocol\n",
    "- Transport independence (UDP/IP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "NFS Server:\n",
    "- Must commit modifications before return results\n",
    "- Generation number in inode and filesystem id in superblock\n",
    "\n",
    "NFS Client:\n",
    "- Additional virtual file system interface in the Linux kernel\n",
    "- Attach remote file system via `mount`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pictures/distributed-file-systems/SunNFS.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Clustered File System **\n",
    "\n",
    "- Additional middleware layers such as the tasks of a file system server can be distributed among a cluster of computers\n",
    "- Example: The Zettabyte File System by Sun Microsystem\n",
    "\n",
    "*Bonwick, Jeff, Matt Ahrens, Val Henson, Mark Maybee, and Mark Shellenbaum. \"The zettabyte file system.\" In Proc. of the 2nd Usenix Conference on File and Storage Technologies, vol. 215. 2003.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\"One of the most striking design principles in modern file systems is the one-to-one association between\n",
    "a file system and a particular storage device (or portion thereof). Volume managers do virtualize\n",
    "the underlying storage to some degree, but in the end, a file system is still assigned to some\n",
    "particular range of blocks of the logical storage device. This is counterintuitive because a file\n",
    "system is intended to virtualize physical storage, and yet there remains a fixed binding between\n",
    "a logical namespace and a specific device (logical or physical, they both look the same to the user).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Design Principles:**\n",
    "- Simple administration: simplify and automate adminstration of storage to a much greater degree\n",
    "- Pooled storage: decouple file systems from physical storage with allocation being done on the pooled storage side rather than the file system side\n",
    "- Dynamic file system size\n",
    "- Always consistenton-disk data\n",
    "- Immense capacity (Prediction in 2003: 16 Exabyte datasets to appear in 10.5 years)\n",
    "- Error detection and correction\n",
    "- Integration of volume manager\n",
    "- Excellent performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pictures/distributed-file-systems/name_space.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pictures/distributed-file-systems/ZFS.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Pararell File Systems **\n",
    "\n",
    "*Ross, Robert, Philip Carns, and David Metheny. \"Parallel file systems.\" In Data Engineering, pp. 143-168. Springer, Boston, MA, 2009.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pictures/distributed-file-systems/PFS.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Fundamental Design Concepts **\n",
    "- Single *namespace*, including files and directories hierarchy\n",
    "- Actual data are distributed over storage servers\n",
    "  - Only large files are split up into contiguous data regions\n",
    "- Metadata regarding namespace and data distribution are stored:\n",
    "  - Dedicated metadata servers (PVFS)\n",
    "  - Distributed across storage servers (CephFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Parallel file access mechanisms **\n",
    "- Shared-file (N-to-1): A single file is created, and all application tasks write to that file (usually to disjoint regions)\n",
    "    - Increased usability: only one file is needed\n",
    "    - Can create lock contention and reduce performance\n",
    "- File-per-process (N-to-N): Each application task creates a separate file, and writes only to that file. \n",
    "    - Avoids lock contention\n",
    "    - Can create massive amount of small files\n",
    "    - Does not support application restart on different number of tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Data Distribution in Parallel File Systems **\n",
    "- Original File: Sequence of Bytes\n",
    "- Sequence of bytes are converted into sequence of offsets (each offset can cover multiple bytes)\n",
    "- Offsets are mapped to objects\n",
    "    - not necessarily ordered mapping\n",
    "    - reversible to allow clients to contact specific PFS server for specific data content\n",
    "- Objects are distributed across PFS servers\n",
    "    - Information about where the objects are is stored at the metadata server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Object Placement **\n",
    "- Round robin is reasonable default solution\n",
    "- Work consistently on most systems\n",
    "- Default solutions for: GPFS, Lustre, PVFS\n",
    "- Potential scalability issue with massive scaling of file servers and file size\n",
    "    - Two dimensional distribution\n",
    "    - Limit number of servers per file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Design Challenges **\n",
    "- Performance\n",
    "  - How well the file system interfaces with applications\n",
    "- Consistency Semantics\n",
    "- Interoperability:\n",
    "  - POSIX/UNIX\n",
    "  - MPI/IO\n",
    "- Fault Tolerance:\n",
    "  - Amplifies due to PFS' multiple storage devices and I/O Path\n",
    "- Management Tools"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
